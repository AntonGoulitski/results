{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "LR = 0.005\n",
    "EPOCHS = 2\n",
    "BATCHSIZE = 32\n",
    "CHANNELS = 64\n",
    "IMAGE_SIZE = 512\n",
    "NBLOCK = 6 \n",
    "DEPTH = 2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from keras.applications.vgg16  import VGG16\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rc('xtick', labelsize=15) \n",
    "plt.rc('ytick', labelsize=15) \n",
    "plt.rc('lines', linewidth=3)\n",
    "plt.rc('font', size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_random_seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"E:\\rsna_n\\rsna-pneumonia-detection-challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RSNA_NORMAL/'\n",
    "image_paths_norm = sorted(list(paths.list_images(directory))) \n",
    "labels_norm = ['0'] * len(image_paths_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RSNA_LUNGOPACITY/'\n",
    "image_paths_pn = sorted(list(paths.list_images(directory))) \n",
    "\n",
    "labels_pn = ['1'] * len(image_paths_pn)\n",
    "\n",
    "image_paths = np.array(image_paths_norm + image_paths_pn)\n",
    "labels = np.concatenate((labels_norm, labels_pn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([1, 2], height=[len(labels_norm), len(labels_pn)], \n",
    "        tick_label=['({0:d} Normal Samples)'.format(len(labels_norm)), \n",
    "                    '({0:d} Pneumonia Samples)'.format(len(labels_pn))], \n",
    "        color=['m', 'g'])\n",
    "\n",
    "plt.title('Number Of Images'.\n",
    "          format(len(labels_norm) + len(labels_pn)))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_dir, X_test_dir, y_train, y_test = \\\n",
    "                                           train_test_split(image_paths, labels, test_size=0.3)\n",
    "\n",
    "X_val_dir, y_val = X_test_dir[:len(X_test_dir) // 2], \\\n",
    "                   y_test[:len(y_test) // 2]\n",
    "\n",
    "X_test_dir, y_test = X_test_dir[len(X_test_dir) // 2:], \\\n",
    "                     y_test[len(y_test) // 2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(np.transpose([X_train_dir, y_train]), \n",
    "                        columns=['filename', 'class'])\n",
    "\n",
    "val_df = pd.DataFrame(np.transpose([X_val_dir, y_val]), \n",
    "                      columns=['filename', 'class'])\n",
    "\n",
    "test_df = pd.DataFrame(np.transpose([X_test_dir, y_test]), \n",
    "                       columns=['filename', 'class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10404 validated image filenames.\n",
      "Found 2229 validated image filenames.\n",
      "Found 2230 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                             zoom_range=0.1, \n",
    "                             height_shift_range=0.05, \n",
    "                             width_shift_range=0.05,\n",
    "                             rotation_range=5)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(train_df,\n",
    "                                        target_size=(224, 224),\n",
    "                                        color_mode='rgb',\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=True)\n",
    "\n",
    "val_gen = test_datagen.flow_from_dataframe(val_df,\n",
    "                                        target_size=(224, 224),\n",
    "                                        color_mode='rgb',\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=False)\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(test_df,\n",
    "                                        target_size=(224, 224),\n",
    "                                        color_mode='rgb',\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                            output_types=(tf.float32, tf.int32),\n",
    "                                            output_shapes=([None, 224, 224, 1], [None, ]))\n",
    "\n",
    "val_data = tf.data.Dataset.from_generator(lambda: val_gen,\n",
    "                                          output_types=(tf.float32, tf.int32),\n",
    "                                          output_shapes=([None, 224, 224, 1], [None, ]))\n",
    "\n",
    "test_data = tf.data.Dataset.from_generator(lambda: test_gen,\n",
    "                                           output_types=(tf.float32, tf.int32),\n",
    "                                           output_shapes=([None, 224, 224, 1], [None, ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_augment = []\n",
    "\n",
    "for image_path in image_paths[:4]:\n",
    "    image = load_img(image_path, target_size=(512, 512))\n",
    "    image = img_to_array(image)\n",
    "    images_to_augment.append(image)\n",
    "    \n",
    "images_to_augment = np.array(images_to_augment)\n",
    "\n",
    "images_augmented = next(datagen.flow(x=images_to_augment,\n",
    "                                batch_size=10,\n",
    "                                shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_data(dataset):\n",
    "\n",
    "    \n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  \n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "(7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.applications.vgg16  import VGG16\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "input_shape=(224, 224, 3)\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=img_input, input_shape=input_shape)\n",
    "x = base_model.output\n",
    "print(base_model.output_shape[1:])\n",
    "x = Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len([0,1])-1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "model = Model(inputs=img_input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy', 'binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import keras.callbacks as kcall\n",
    "weight_path=\"{}_weights.best.hdf5\".format('vgg16RSNAl')\n",
    "weight_path\n",
    "class LossHistory(kcall.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "        self.epochs_losses = []\n",
    "        self.epochs_acc = []\n",
    "        self.epochs_val_losses = []\n",
    "        self.epochs_val_acc = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.batch_losses.append(logs.get('loss'))\n",
    "        self.batch_acc.append(logs.get('acc'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epochs_losses.append(logs.get('loss'))\n",
    "        self.epochs_acc.append(logs.get('acc'))\n",
    "        self.epochs_val_losses.append(logs.get('val_loss'))\n",
    "        self.epochs_val_acc.append(logs.get('val_acc'))\n",
    "history = LossHistory()\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "\n",
    "callbacks_list = [checkpoint, early, history]\n",
    "callbacks_list\n",
    "from keras.optimizers import SGD\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "650/650 [==============================] - 221s 339ms/step - loss: 0.3139 - accuracy: 0.8670 - precision: 0.7830 - recall: 0.7323 - val_loss: 0.3441 - val_accuracy: 0.8669 - val_precision: 0.8635 - val_recall: 0.7988\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34407, saving model to vgg16RSNAl_weights.best.hdf5\n",
      "Epoch 2/20\n",
      "650/650 [==============================] - 224s 344ms/step - loss: 0.2320 - accuracy: 0.9126 - precision: 0.8829 - recall: 0.8104 - val_loss: 0.2393 - val_accuracy: 0.9277 - val_precision: 0.8917 - val_recall: 0.8300\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34407 to 0.23931, saving model to vgg16RSNAl_weights.best.hdf5\n",
      "Epoch 3/20\n",
      "650/650 [==============================] - 228s 351ms/step - loss: 0.2106 - accuracy: 0.9237 - precision: 0.8968 - recall: 0.8426 - val_loss: 0.0371 - val_accuracy: 0.9232 - val_precision: 0.9031 - val_recall: 0.8487\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23931 to 0.03705, saving model to vgg16RSNAl_weights.best.hdf5\n",
      "Epoch 4/20\n",
      "650/650 [==============================] - 217s 334ms/step - loss: 0.1970 - accuracy: 0.9251 - precision: 0.9078 - recall: 0.8523 - val_loss: 0.0736 - val_accuracy: 0.9336 - val_precision: 0.9110 - val_recall: 0.8567\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03705\n",
      "Epoch 5/20\n",
      "650/650 [==============================] - 216s 332ms/step - loss: 0.1890 - accuracy: 0.9298 - precision: 0.9140 - recall: 0.8603 - val_loss: 0.4683 - val_accuracy: 0.9367 - val_precision: 0.9164 - val_recall: 0.8634\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03705\n",
      "Epoch 6/20\n",
      "650/650 [==============================] - 214s 329ms/step - loss: 0.1782 - accuracy: 0.9349 - precision: 0.9188 - recall: 0.8673 - val_loss: 0.3243 - val_accuracy: 0.9331 - val_precision: 0.9194 - val_recall: 0.8705\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03705\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator = train_gen,                    \n",
    "                    epochs=20,                    \n",
    "                    steps_per_epoch=train_gen.n//train_gen.batch_size,                    \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.n//val_gen.batch_size,                    \n",
    "                    shuffle=False,\n",
    "                    callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "#lr_scheduler = LearningRateScheduler(lr_decay, 1)\n",
    "csv_logger = CSVLogger(filename='RSNA_VGG16.csv')\n",
    "model_checkpoint = ModelCheckpoint(filepath='RSNA_VGG16{epoch:04d}.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RSNA_VGG16.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2d03dac4f7c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mseven_layer_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RSNA_VGG16.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\df_env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    642\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m             )\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RSNA_VGG16.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "seven_layer_aug = pd.read_csv(\"RSNA_VGG16.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(results, title, ylim=None, figsize=(15, 15)):\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for name, result in results:\n",
    "        val = plt.plot(range(len((result['epoch']))), result['val_loss'],\n",
    "                       '--', label=name.title()+', Validation', lw=3.0)\n",
    "        plt.plot(range(len((result['epoch']))), result['loss'], color=val[0].get_color(),\n",
    "                 label=name.title()+', Training', lw=3.0)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylim(ylim)\n",
    "    plt.grid(lw=2, ls='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(results, title, x_range=20, figsize=(15, 15)):\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    for name, result in results:\n",
    "        val = plt.plot(range(len((result['epoch']))), result['val_accuracy'],\n",
    "                       '--', label=name.title()+', Validation', lw=3.0)\n",
    "        plt.plot(range(len((result['epoch']))), result['accuracy'], color=val[0].get_color(),\n",
    "                 label=name.title()+', Training', lw=3.0)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(lw=2, ls='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
